{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Input, Dense, GRU, Embedding,Dropout,BatchNormalization\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "entry=[]\n",
    "fields=[]\n",
    "references=[]\n",
    "year=''\n",
    "index=''\n",
    "d={'index':[],\n",
    "  'year':[],\n",
    "  'references':[]\n",
    "  }\n",
    "with open('outputacm.txt','r') as file :\n",
    "    line=next(file)\n",
    "    while line :\n",
    "        if not line.startswith('\\n'):\n",
    "            if line.startswith('#%'):\n",
    "                references.append(''.join(filter(lambda x: x.isdigit(), line)))\n",
    "            if line.startswith('#t'):\n",
    "                year=''.join(filter(lambda x: x.isdigit(),line))\n",
    "            if line.startswith('#index'):\n",
    "                index=''.join(filter(lambda x: x.isdigit(),line))\n",
    "        else :\n",
    "            d['index'].append(index)\n",
    "            d['year'].append(year)\n",
    "            d['references'].append(references)\n",
    "            references=[]\n",
    "        line=next(file,None)\n",
    "\n",
    "df=pd.DataFrame(d)\n",
    "dd=dict(zip(df['index'],df['year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>[207703, 362949, 357613, 226571, 298457, 52492...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>[248365, 322246, 98581, 185358, 242092, 251593...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>[298257, 394709, 581170, 253404, 347870, 58216...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>[302483, 285956, 231951, 309024, 231811, 34414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             references\n",
       "year                                                   \n",
       "2007  [207703, 362949, 357613, 226571, 298457, 52492...\n",
       "2008  [248365, 322246, 98581, 185358, 242092, 251593...\n",
       "2009  [298257, 394709, 581170, 253404, 347870, 58216...\n",
       "2010  [302483, 285956, 231951, 309024, 231811, 34414...\n",
       "2018                                                 []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_by_year=df.groupby('year')['references'].agg(sum).to_frame()\n",
    "grouped_by_year.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_year['references'].apply(lambda z: dict(Counter(z))).to_frame().to_csv('all_pappers_references.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('all_pappers_references.csv',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "df['references']=df['references'].apply(lambda z: ast.literal_eval(z))\n",
    "dd=dict(zip(df['year'],df['references']))\n",
    "diff=pd.DataFrame(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff=diff.fillna(0)\n",
    "diff.to_csv('tt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>1900</th>\n",
       "      <th>1941</th>\n",
       "      <th>1947</th>\n",
       "      <th>1949</th>\n",
       "      <th>1950</th>\n",
       "      <th>1951</th>\n",
       "      <th>1952</th>\n",
       "      <th>1953</th>\n",
       "      <th>1954</th>\n",
       "      <th>...</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99978</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41945.0</td>\n",
       "      <td>38263.0</td>\n",
       "      <td>22535.0</td>\n",
       "      <td>30777.0</td>\n",
       "      <td>26467.0</td>\n",
       "      <td>43565.0</td>\n",
       "      <td>60260.0</td>\n",
       "      <td>63111.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1     1900  1941  1947  1949  1950  1951  1952  1953  1954  ...   \\\n",
       "99978   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "9998    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "99986   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "99987   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "Total   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...    \n",
       "\n",
       "          2002     2003     2004     2005     2006     2007     2008     2009  \\\n",
       "99978      0.0      0.0      0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "9998       0.0      0.0      0.0      0.0      0.0      1.0      4.0      5.0   \n",
       "99986      0.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "99987      0.0      0.0      0.0      0.0      0.0      2.0      0.0      0.0   \n",
       "Total  41945.0  38263.0  22535.0  30777.0  26467.0  43565.0  60260.0  63111.0   \n",
       "\n",
       "        2010  2018  \n",
       "99978    0.0   0.0  \n",
       "9998     0.0   0.0  \n",
       "99986    0.0   0.0  \n",
       "99987    0.0   0.0  \n",
       "Total  480.0   0.0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.loc['Total']=diff.sum()\n",
    "diff.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "row=diff.iloc[-1]\n",
    "plt.figure(figsize=(14,6))\n",
    "row.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('tt.csv')\n",
    "coll = df.columns.tolist()\n",
    "df2 = df[coll[17:-1]]\n",
    "col = df2.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>1969</th>\n",
       "      <th>1970</th>\n",
       "      <th>...</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147943</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1961  1962  1963  1964  1965  1966  1967  1968  1969  1970  ...   \\\n",
       "147943   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "\n",
       "        2001  2002  2003  2004  2005  2006  2007  2008  2009  2010  \n",
       "147943   0.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0  \n",
       "\n",
       "[1 rows x 50 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>1969</th>\n",
       "      <th>1970</th>\n",
       "      <th>...</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1961  1962  1963  1964  1965  1966  1967  1968  1969  1970  ...   2001  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "\n",
       "   2002  2003  2004      2005  2006      2007      2008      2009  2010  \n",
       "0   0.0   0.0   0.0  0.022222   0.0  0.000000  0.018018  0.000000   0.0  \n",
       "1   0.0   0.0   0.0  0.022222   0.0  0.014493  0.000000  0.000000   0.0  \n",
       "2   0.0   0.0   0.0  0.000000   0.0  0.000000  0.000000  0.008065   0.0  \n",
       "3   0.0   0.0   0.0  0.044444   0.0  0.000000  0.018018  0.000000   0.0  \n",
       "4   0.0   0.0   0.0  0.000000   0.0  0.000000  0.000000  0.008065   0.0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scaler = MinMaxScaler()\n",
    "#scaled_data = scaler.fit_transform(df2)\n",
    "#df_scaled = pd.DataFrame(data=scaled_data,columns = df2.columns.tolist(), index = df2.index.tolist() )\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df2)\n",
    "#print(x_scaler.data_max_)\n",
    "df_scaled=pd.DataFrame(scaled_data,columns=col)\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147944, 50)\n",
      "(147944, 50)\n"
     ]
    }
   ],
   "source": [
    "print(df2.shape)\n",
    "print(df_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data,train_rate=0.8):\n",
    "    \"\"\"\n",
    "    Spliting the dataset to train and test set\n",
    "    \"\"\"\n",
    "    \n",
    "    msk = np.random.rand(len(data)) < train_rate\n",
    "    return data[msk],data[~msk]\n",
    "\n",
    "#train_set,test_set = split_data(df2) #example of usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_seq(data,seq_size,batch_size,f_years = 5):\n",
    "    \"\"\"\n",
    "    Generator function that transforms the data to sequences and return them to batches\n",
    "    \n",
    "    data_len the number of articles\n",
    "    sequence_length number of years that can used for training\n",
    "    f_years  years predicting into the futu\n",
    "    \"\"\"\n",
    "    \n",
    "    data_len = data.shape[0] #the number of articles\n",
    "    sequence_length = data.shape[1]-seq_size-f_years-1 #the number of years that can used for training\n",
    "    \n",
    "    while True:\n",
    "        idx = [random.randint(0,data_len) for i in range(seq_size)]\n",
    "        \n",
    "        x_shape = (batch_size, sequence_length, num_x_signals)\n",
    "        x_batch = np.zeros(shape=x_shape, dtype=np.float16)\n",
    "        \n",
    "        y_shape = (batch_size, sequence_length, num_y_signals)\n",
    "        y_batch = np.zeros(shape=y_shape, dtype=np.float16)\n",
    "        for key,row in enumerate(idx):\n",
    "            obs = data.iloc[row]\n",
    "            x ,y =[],[]\n",
    "            for i in range(data.shape[1]-seq_size-f_years-1):\n",
    "                train_data = obs[i:(i+seq_size)]\n",
    "                target_data = obs[(i+seq_size):(i+seq_size+f_years)]\n",
    "                x.append(train_data)\n",
    "                y.append(target_data)\n",
    "            \n",
    "            x_batch[key] = np.array(x)\n",
    "            y_batch[key] = np.array(y)\n",
    "            \n",
    "        yield x_batch,y_batch\n",
    "\n",
    "seq_size = 9\n",
    "batch_size = 10\n",
    "num_x_signals = 9 #random, we can change that\n",
    "num_y_signals =5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 35, 9)\n",
      "(10, 35, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#example of generating a batch\n",
    "generator=to_seq(df2,seq_size,batch_size)\n",
    "x,y=next(generator)\n",
    "print(x.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_loc(data):\n",
    "    x=[]\n",
    "    f_years=5\n",
    "    for i in range(data.shape[0]-seq_size-f_years-1):\n",
    "        train_data = data[i:(i+seq_size)]\n",
    "        x.append(train_data)\n",
    "    return x\n",
    "\n",
    "def y_loc(data):\n",
    "    y=[]\n",
    "    f_years=5\n",
    "    for i in range(data.shape[0]-seq_size-f_years-1):\n",
    "        target_data = data[(i+seq_size):(i+seq_size+f_years)]\n",
    "        y.append(target_data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_val_set(data):\n",
    "    '''\n",
    "    Create validation set to test the model\n",
    "    '''\n",
    "    locs = map(lambda x:data.iloc[x],range(data.shape[0]))\n",
    "    loc_list = np.array(list(locs))\n",
    "    x = map(x_loc,loc_list)\n",
    "    y = map(y_loc,loc_list)\n",
    "    #validation_data =(np.array(list(x)),np.array(list(y)))\n",
    "    return (np.array(list(x)),np.array(list(y)))\n",
    "\n",
    "#validation_data = create_val_set(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoint = '23_checkpoint.keras'\n",
    "callback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n",
    "                                      monitor='val_loss',\n",
    "                                      verbose=1,\n",
    "                                      save_weights_only=True,\n",
    "                                      save_best_only=True)\n",
    "\n",
    "callback_early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                        patience=5, verbose=1)\n",
    "\n",
    "callback_tensorboard = TensorBoard(log_dir='./23_logs/',\n",
    "                                   histogram_freq=0,\n",
    "                                   write_graph=False)\n",
    "\n",
    "callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                       factor=0.1,\n",
    "                                       min_lr=1e-4,\n",
    "                                       patience=0,\n",
    "                                       verbose=1)\n",
    "\n",
    "callbacks = [callback_early_stopping,\n",
    "             callback_checkpoint,\n",
    "             callback_tensorboard,\n",
    "             callback_reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(unit_size):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=unit_size,\n",
    "              return_sequences=True,\n",
    "              input_shape=(None, num_x_signals,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Dense(num_y_signals, activation='sigmoid'))\n",
    "    optimizer = RMSprop(lr=1e-3)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "#tf_model = create_model(data_key['unit_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,name):\n",
    "    model_json = model.to_json()\n",
    "    with open(name+'.json','w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1010\n",
      "Epoch 00001: val_loss improved from inf to 0.01280, saving model to 23_checkpoint.keras\n",
      "100/100 [==============================] - 85s 850ms/step - loss: 0.1001 - val_loss: 0.0128\n",
      "Epoch 2/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030\n",
      "Epoch 00002: val_loss improved from 0.01280 to 0.00028, saving model to 23_checkpoint.keras\n",
      "100/100 [==============================] - 98s 980ms/step - loss: 0.0030 - val_loss: 2.8353e-04\n",
      "Epoch 3/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2.3968e-04\n",
      "Epoch 00003: val_loss improved from 0.00028 to 0.00016, saving model to 23_checkpoint.keras\n",
      "100/100 [==============================] - 99s 985ms/step - loss: 2.3751e-04 - val_loss: 1.6415e-04\n",
      "Epoch 4/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 7.9045e-05\n",
      "Epoch 00004: val_loss improved from 0.00016 to 0.00016, saving model to 23_checkpoint.keras\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "100/100 [==============================] - 102s 1s/step - loss: 7.8531e-05 - val_loss: 1.6208e-04\n",
      "Epoch 5/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.3166e-04\n",
      "Epoch 00005: val_loss improved from 0.00016 to 0.00016, saving model to 23_checkpoint.keras\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "100/100 [==============================] - 81s 809ms/step - loss: 1.3173e-04 - val_loss: 1.5686e-04\n",
      "Epoch 6/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 9.9892e-05- ETA: 4s\n",
      "Epoch 00006: val_loss improved from 0.00016 to 0.00014, saving model to 23_checkpoint.keras\n",
      "100/100 [==============================] - 72s 723ms/step - loss: 9.9118e-05 - val_loss: 1.4265e-04\n",
      "Epoch 7/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 8.8461e-05\n",
      "Epoch 00007: val_loss improved from 0.00014 to 0.00014, saving model to 23_checkpoint.keras\n",
      "100/100 [==============================] - 89s 886ms/step - loss: 8.7645e-05 - val_loss: 1.4032e-04\n",
      "Epoch 8/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.7047e-04\n",
      "Epoch 00008: val_loss did not improve\n",
      "100/100 [==============================] - 104s 1s/step - loss: 1.6908e-04 - val_loss: 1.5569e-04\n",
      "Epoch 9/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.5445e-04\n",
      "Epoch 00009: val_loss did not improve\n",
      "100/100 [==============================] - 81s 810ms/step - loss: 1.5358e-04 - val_loss: 1.5693e-04\n",
      "Epoch 10/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2.0861e-04\n",
      "Epoch 00010: val_loss did not improve\n",
      "100/100 [==============================] - 103s 1s/step - loss: 2.0690e-04 - val_loss: 1.5466e-04\n",
      "Epoch 11/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 9.8008e-05\n",
      "Epoch 00011: val_loss did not improve\n",
      "100/100 [==============================] - 111s 1s/step - loss: 9.7133e-05 - val_loss: 1.7494e-04\n",
      "Epoch 12/100\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.3186e-04\n",
      "Epoch 00012: val_loss did not improve\n",
      "100/100 [==============================] - 123s 1s/step - loss: 1.3076e-04 - val_loss: 2.2214e-04\n",
      "Epoch 00012: early stopping\n",
      "29738/29738 [==============================] - 59s 2ms/step\n",
      "[('10_100_9_100_128', 0.00022213822557246197)]\n"
     ]
    }
   ],
   "source": [
    "data_grid = {\n",
    "    'unit_size': [128],\n",
    "    'batch': [10],\n",
    "    'seq': [9],\n",
    "    'ep':[100],\n",
    "    'steps_per_ep':[100]\n",
    "}\n",
    "data_search = ParameterGrid(data_grid)\n",
    "\n",
    "\n",
    "res =[]\n",
    "res_int=[]\n",
    "\n",
    "train_set,test_set = split_data(df_scaled)\n",
    "for count, data_key in enumerate(data_search):\n",
    "    seq_size = data_key['seq']\n",
    "    batch_size = data_key['batch']\n",
    "    num_x_signals = seq_size #random, we can change that\n",
    "    num_y_signals =5\n",
    "    res.append('_'.join( str(key) for i,key in data_key.items() ) )\n",
    "\n",
    "    generator=to_seq(train_set,seq_size,batch_size)\n",
    "    validation_data = create_val_set(test_set)\n",
    "    tf_model = create_model(data_key['unit_size'])\n",
    "    #tf_model.summary()\n",
    "    tf_model.fit_generator(generator=generator,\n",
    "                    epochs=data_key['ep'],\n",
    "                    steps_per_epoch=data_key['steps_per_ep'],\n",
    "                    validation_data=validation_data,\n",
    "                    callbacks=callbacks)\n",
    "    \n",
    "    res_int.append(tf_model.evaluate(x=validation_data[0],\n",
    "                        y=validation_data[1]))\n",
    "    \n",
    "    save_model(tf_model,res[-1])   \n",
    " \n",
    "\n",
    "print(list(zip(res,res_int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,h1=create_val_set(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=tf_model.predict(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29636, 36, 5)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
